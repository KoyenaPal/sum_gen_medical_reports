{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"HiyLX9pMrxym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651409660085,"user_tz":240,"elapsed":5280,"user":{"displayName":"Koyena Pal","userId":"01468633587307250970"}},"outputId":"9ced9484-4d8f-449a-ab07-7a13b8dae4e4"},"source":["!pip3 install pickle5\n","import pickle5 as pickle\n","import pandas as pd\n","import re\n","import csv"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Gvl97yEsWth","executionInfo":{"status":"ok","timestamp":1651409662134,"user_tz":240,"elapsed":2056,"user":{"displayName":"Koyena Pal","userId":"01468633587307250970"}},"outputId":"4c5fdf9d-64fb-456c-dcf5-52706c7b92ba"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)\n","root_dir = \"/content/gdrive/My Drive/masters_thesis/\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"XCQI4zkkr_pn"},"source":["def unpickle_data(filename):\n","    with open(filename, \"rb\") as fh:\n","      data = pickle.load(fh)\n","      return data\n","    #return unpickled_df\n","notes_file = root_dir + \"notes_full.pickle\"\n","admissions_file = root_dir + \"admissions.pickle\"\n","# notes_df = unpickle_data(notes_file)\n","# admissions_df = unpickle_data(admissions_file)\n","# notes_df.to_csv(root_dir + \"notes.csv\", index=False)\n","# admissions_df.to_csv(root_dir + \"admissions.csv\", index=False)\n","#!cp \"notes.csv\" base_dir\n","#!cp \"admissions.csv\" base_dir\n","#print(unpickle_data(admissions_file).head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_data(filename):\n","  df = pd.read_csv(filename)\n","  print(df.head(1))\n","  print(df.dtypes)\n","  print(df.index)\n","  print(df.columns)\n","  return df\n","\n","notes_file = root_dir + \"notes.csv\"\n","#admissions_file = root_dir + \"admissions.csv\"\n","notes_df = read_data(notes_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5He6sI0TDK9_","executionInfo":{"status":"ok","timestamp":1651409734982,"user_tz":240,"elapsed":72855,"user":{"displayName":"Koyena Pal","userId":"01468633587307250970"}},"outputId":"4e3b272e-3cf1-4435-ef49-04189e71cea1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["   row_id  subject_id   hadm_id   chartdate charttime storetime  \\\n","0       1       23224  174680.0  2147-12-05       NaN       NaN   \n","\n","            category description  cgid iserror  \\\n","0  Discharge summary      Report   NaN           \n","\n","                                                text  \n","0  Admission Date:  [**2823-9-29**]              ...  \n","row_id           int64\n","subject_id       int64\n","hadm_id        float64\n","chartdate       object\n","charttime       object\n","storetime       object\n","category        object\n","description     object\n","cgid           float64\n","iserror         object\n","text            object\n","dtype: object\n","RangeIndex(start=0, stop=2078705, step=1)\n","Index(['row_id', 'subject_id', 'hadm_id', 'chartdate', 'charttime',\n","       'storetime', 'category', 'description', 'cgid', 'iserror', 'text'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["now_df = read_data(root_dir + \"setup6_training.csv\")\n","print(len(now_df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZea7eCmDqTQ","executionInfo":{"status":"ok","timestamp":1651410164763,"user_tz":240,"elapsed":7975,"user":{"displayName":"Koyena Pal","userId":"01468633587307250970"}},"outputId":"7435b38f-47ee-4647-9ba3-95c5caf6eeb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["    hadm_id                                             source  \\\n","0  133857.0  69 year old male who on fishing trip alone tod...   \n","\n","                                              target  \n","0  HPI: This is a 69 year old male who is primari...  \n","hadm_id    float64\n","source      object\n","target      object\n","dtype: object\n","RangeIndex(start=0, stop=5981, step=1)\n","Index(['hadm_id', 'source', 'target'], dtype='object')\n","5981\n"]}]},{"cell_type":"code","source":["notes_df = notes_df[notes_df[\"iserror\"] == \" \"]"],"metadata":{"id":"MRiCDR0DYtRA"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v1u_-vB8VVDV","executionInfo":{"status":"ok","timestamp":1647670349049,"user_tz":240,"elapsed":263692,"user":{"displayName":"Koyena Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_e3wK4u2NszAiUDUMpC_CA8vzjTPbD9hXBfzP=s64","userId":"01468633587307250970"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"47f9d863-48be-4fda-db21-6041805d1409"},"source":["def notes_info(notes_df):\n","  #print(\"notes size\", len(notes_df))\n","  #print(\"CATEGORY EXAMPLE\")\n","  #print(len(notes_df[\"category\"].unique()))\n","  #print(\"DESCRIPTION EXAMPLE\")\n","  #desc_size = notes_df[\"description\"].unique()\n","  #print(\"description size\", len(desc_size))\n","  #for i in range(len(desc_size)):\n","    #print(desc_size[i])\n","  #print(notes_df[\"description\"].unique())\n","  # print(\"TEXT EXAMPLE\")\n","  # print(notes_df[\"text\"][0])\n","  discharge_summary_df = notes_df.loc[notes_df[\"category\"] == \"Nursing\"]\n","  print(len(discharge_summary_df))\n","  for i in range(1):\n","    print(discharge_summary_df.iloc[i][\"text\"])\n","\n","def get_examples(notes_df, text_file):\n","  cat_examples = []\n","  with open(text_file, 'w') as txtfile:\n","    categories = notes_df[\"category\"].unique()\n","    for c in categories:\n","      c_str = \"Category: \" + c + \"\\n\"\n","      part_df = notes_df.loc[notes_df[\"category\"] == c]\n","      txtfile.write(c_str)\n","      for i in range(5):\n","        ex_str = \"Example \" + str(i + 1) + \":\\n\" \n","        txtfile.write(ex_str)\n","        txtfile.write(part_df.iloc[i][\"text\"])\n","\n","\n","\n","def discharge_summary_info(notes_df):\n","  discharge_summary_df = notes_df.loc[notes_df[\"category\"] == \"Discharge summary\"]\n","  print(\"Length of discharge df\", len(discharge_summary_df))\n","  sections_to_count = {}\n","  sections_to_length = {}\n","  hadm_to_final_divides = {}\n","  for i in range(len(discharge_summary_df)):\n","    hadm_id = discharge_summary_df.iloc[i][\"hadm_id\"]\n","    text = discharge_summary_df.iloc[i][\"text\"]\n","    sections = re.split('([a-zA-Z]+):\\n|([a-zA-Z]+\\s[a-zA-Z]+):\\n', text)\n","    section = \"\"\n","    final_divides = {}\n","    for i in range(1,len(sections)):\n","      if sections[i] != None:\n","        if section != \"\":\n","          final_divides[section] = sections[i]\n","          section = \"\"\n","        else:\n","          section = sections[i]\n","    for key, value in final_divides.items():\n","      sentence_len = len(value.split(\".\"))\n","      if key in sections_to_count:\n","        curr_counter = sections_to_count[key]\n","        total_length = sections_to_length[key]\n","        curr_counter += 1\n","        total_length += sentence_len\n","        sections_to_count[key] = curr_counter\n","        sections_to_length[key] = total_length\n","      else:\n","        sections_to_count[key] = 1\n","        sections_to_length[key] = sentence_len\n","    hadm_to_final_divides[hadm_id] = final_divides\n","  return sections_to_count, sections_to_length, hadm_to_final_divides\n","\n","def nursing_info(notes_df):\n","  nursing_df = notes_df.loc[notes_df[\"category\"] == \"Nursing\"]\n","  print(len(nursing_df))\n","  for i in range(1):\n","    text = nursing_df.iloc[i][\"text\"]\n","    sections = re.split('(\\w+:)', text)\n","\n","def grouping_by_patients(notes_df):\n","  filter_df = notes_df[notes_df.iserror != '1']\n","  #print(len(filter_df))\n","  #categories = [\"Discharge summary\", \"Nursing\"]\n","  #specific_rows = filter_df[filter_df.category.isin(categories)]\n","  #print(len(specific_rows)) #there are 278359 that are either discharge summary or nursing\n","  # no_error_rows = specific_rows[specific_rows.iserror == 'false']\n","  #print(len(no_error_rows))\n","  hadm_to_discharge = {}\n","  hadm_to_nursing = {}\n","  for index, row in filter_df.iterrows():\n","    hadm_id = row['hadm_id']\n","    curr_category = row[\"category\"]\n","    if (curr_category == \"Nursing\"):\n","      curr_date = row[\"chartdate\"]\n","      curr_text = row[\"text\"]\n","      if hadm_id in hadm_to_nursing:\n","        curr_nursing = hadm_to_nursing[hadm_id]\n","        curr_nursing.append((curr_date,curr_text))\n","        hadm_to_nursing[hadm_id] = curr_nursing\n","      else:\n","        hadm_to_nursing[hadm_id] = [(curr_date,curr_text)]\n","    if (curr_category == \"Discharge summary\"):\n","      curr_date = row[\"chartdate\"]\n","      curr_text = row[\"text\"]\n","      if hadm_id in hadm_to_discharge:\n","        curr_discharge = hadm_to_discharge[hadm_id]\n","        curr_discharge.append((curr_date,curr_text))\n","        hadm_to_discharge[hadm_id] = curr_discharge\n","      else:\n","        hadm_to_discharge[hadm_id] = [(curr_date,curr_text)]\n","  return hadm_to_discharge, hadm_to_nursing\n","\n","\n","# https://mimic.mit.edu/docs/iii/tables/noteevents/\n","#notes_file = root_dir + \"notes.csv\"\n","#admissions_file = root_dir + \"admissions.csv\"\n","#notes_df = read_data(notes_file)\n","#text_file = root_dir + \"category_examples.txt\"\n","#get_examples(notes_df, text_file)\n","\n","#nursing_info(notes_df)\n","hadm_to_discharge, hadm_to_nursing = grouping_by_patients(notes_df)\n","sections_to_count, sections_to_length, hadm_to_final_divides = discharge_summary_info(notes_df)\n","\n","count_filepath = root_dir  + \"updated_sections_to_count.csv\"\n","len_filepath = root_dir  + \"updated_sections_to_length.csv\"\n","avg_filepath = root_dir  + \"updated_sections_to_avg_length.csv\"\n","hadm_discharge_file_path = root_dir  + \"hadm_to_discharge.csv\"\n","with open(count_filepath, 'w') as f:\n","  for key in sections_to_count.keys():\n","    f.write(\"%s, %s\\n\" % (key, sections_to_count[key]))\n","\n","with open(len_filepath, 'w') as f:\n","  for key in sections_to_length.keys():\n","    f.write(\"%s, %s\\n\" % (key, sections_to_length[key]))\n","\n","sections_to_avg_length = {}\n","for key, val in sections_to_count.items():\n","  total_length = sections_to_length[key]\n","  avg_length = float(total_length) / float(val)\n","  sections_to_avg_length[key] = avg_length\n","\n","with open(avg_filepath, 'w') as f:\n","  f.write(\"%s, %s\\n\" % (\"Section\", \"Avg_Num_Sentences\"))\n","  for key in sections_to_avg_length.keys():\n","    f.write(\"%s, %s\\n\" % (key, sections_to_avg_length[key]))\n","\n","# with open(hadm_discharge_file_path, 'w') as f:\n","#   f.write(\"%s, %s\\n\" % (\"hadm_id\", \"discharge_summary\"))\n","#   for key in hadm_to_discharge.keys():\n","#     f.write(\"%s, %s\\n\" % (key, hadm_to_discharge[key][-1][1]))\n","\n","list_of_hadm_ids = []\n","for key in hadm_to_discharge.keys():\n","  list_of_hadm_ids.append(key)\n","\n","# with open(hadm_discharge_file_path, 'w') as csvfile:\n","#     header_key = ['hadm_id', 'discharge_summary']\n","#     new_val = csv.DictWriter(csvfile, fieldnames=header_key)\n","#     new_val.writeheader()\n","#     for key in hadm_to_discharge.keys():\n","#       list_of_hadm_ids.append(key)\n","#       new_val.writerow({'hadm_id': key, 'discharge_summary': hadm_to_discharge[key][-1][1]})\n","\n","\n","#read_data(admissions_file)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of discharge df 55177\n"]}]},{"cell_type":"code","source":["def summarize_text(paragraph):\n","  counter = 0\n","  max_counter = 3\n","  summary_text = \"\"\n","  sentences = paragraph.split(\".\")\n","  for i in sentences:\n","    if (counter < max_counter):\n","      curr_sentence = i + \".\"\n","      summary_text += curr_sentence\n","      counter += 1\n","    else:\n","      break\n","  return summary_text\n","\n","def get_final_summary(section_dict):\n","  summaries = []\n","  for key,value in section_dict.items():\n","    summary = summarize_text(value)\n","    summary_lines = summary.split(\".\")\n","    summaries.append(summary)\n","  return summaries\n","\n","def get_dict_str(section_dict):\n","  text = \"\"\n","  for key,value in section_dict.items():\n","    text += key + \": \" + value + \" \"\n","  return text"],"metadata":{"id":"yKeYdPFdJd_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#final_discharge_df = pd.read_csv(hadm_discharge_file_path)\n","def create_setup1(hadm_to_nursing, file_to_write):\n","  fieldnames = [\"hadm_id\", \"source\", \"target\", \"discharge_summary\"]\n","  with open(file_to_write, 'w') as csvfile:\n","    csvwriter = csv.DictWriter(csvfile, delimiter=',', fieldnames=fieldnames)\n","    csvwriter.writerow(dict((fn,fn) for fn in fieldnames))\n","    #writer.writerow([\"Source\", \"Target\"])\n","    test_array = []\n","    counter = 0\n","    print(\"length of list of hadm ids\", list_of_hadm_ids)\n","    for row in list_of_hadm_ids:\n","      if (counter == 9999):\n","        break\n","      hadm_id = row\n","      if (hadm_id in hadm_to_nursing):\n","        curr_nursing = hadm_to_nursing[hadm_id]\n","        total_nursing = \"\"\n","        for n in curr_nursing:\n","          total_nursing += \"\\n\" + n[1]\n","        test_array.append({\"source\": total_nursing, \"target\": hadm_to_discharge[hadm_id][-1][1], \"discharge_summary\": hadm_to_discharge[hadm_id][-1][1], \"hadm_id\": hadm_id})\n","        counter += 1\n","          #writer.writerow({sources[t], targets[t]})\n","    for row in test_array:\n","      csvwriter.writerow(row)\n","\n","file_name = root_dir + \"setup1_nursing_discharge.csv\"\n","#create_setup1(hadm_to_nursing, file_name)\n"],"metadata":{"id":"rQZJdwJbHvpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import re  \n","import nltk  \n","# import string\n","# import heapq\n","!pip install sumy\n","from sumy.nlp.stemmers import Stemmer\n","import pandas\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from sumy.utils import get_stop_words\n","from sumy.nlp.stemmers import Stemmer\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer as sumytoken\n","\n","from sumy.summarizers.luhn import LuhnSummarizer\n","\n","\n","def luhn_summarizer(text, stemmer, LANGUAGE, SENTENCES_COUNT):\n","    parser = PlaintextParser.from_string(text, sumytoken(LANGUAGE))\n","    summarizer_luhn = LuhnSummarizer(stemmer)\n","    stop_words = get_stop_words(LANGUAGE)\n","    complete_stop_words = set([\"Assessment\", \"Response\", \"Plan\", \"Action\"])\n","    for i in stop_words:\n","      complete_stop_words.add(i)\n","    summarizer_luhn.stop_words = complete_stop_words\n","    sentences = []\n","    for sentence in summarizer_luhn(parser.document, SENTENCES_COUNT):\n","        a = sentence\n","        sentences.append(str(a))\n","    return \" \".join(sentences)\n","\n","LANGUAGE = \"english\"\n","SENTENCES_COUNT = 3\n","stemmer = Stemmer(LANGUAGE)\n","\n","import csv\n","\n","modified_setup2_filepath = root_dir + \"modified_setup2_luhn_discharge.csv\"\n","\n","\n","def create_modified_setup2(modified_setup2_filepath):\n","  with open(modified_setup2_filepath, 'w') as csvfile:\n","    fieldnames = [\"hadm_id\", \"source\", \"target\", \"discharge_summary\"]\n","    csvwriter = csv.DictWriter(csvfile, delimiter=',', fieldnames=fieldnames)\n","    csvwriter.writerow(dict((fn,fn) for fn in fieldnames))\n","    counter = 0\n","    test_array = []\n","    for row in list_of_hadm_ids:\n","      if (counter == 9999):\n","        break\n","      hadm_id = row\n","      if (hadm_id in hadm_to_nursing):\n","        curr_nursing = hadm_to_nursing[hadm_id]\n","        total_nursing = \"\"\n","        if len(curr_nursing) == 1:\n","          total_nursing = curr_nursing[0][1]\n","        elif len(curr_nursing) >= 2:\n","          total_nursing = curr_nursing[0][1]\n","          total_nursing = \"\\n\" + curr_nursing[-1][1]\n","        target_source = hadm_to_discharge[hadm_id][-1][1]\n","        luhn_summary = luhn_summarizer(target_source, stemmer, LANGUAGE, SENTENCES_COUNT)\n","        test_array.append({\"source\": total_nursing, \"target\": luhn_summary, \"discharge_summary\": target_source, \"hadm_id\": hadm_id})\n","        counter += 1\n","    for row in test_array:\n","      csvwriter.writerow(row)\n","\n","#create_modified_setup2(modified_setup2_filepath)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejn3TbRTlsEd","executionInfo":{"status":"ok","timestamp":1647586760248,"user_tz":240,"elapsed":682873,"user":{"displayName":"Koyena Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_e3wK4u2NszAiUDUMpC_CA8vzjTPbD9hXBfzP=s64","userId":"01468633587307250970"}},"outputId":"0fd815d5-bc67-44a3-a94f-7cb3524c215f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sumy in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.6.2)\n","Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.7/dist-packages (from sumy) (22.3.5)\n","Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from sumy) (2.23.0)\n","Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from sumy) (3.2.5)\n","Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.1.20)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (3.0.4)\n","Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (4.2.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.0.2->sumy) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pycountry>=18.2.23->sumy) (57.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (1.24.3)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["setup3_filepath = root_dir  + \"setup3_sentence_3_summary.csv\"\n","modified_setup3_filepath = root_dir  + \"modified_setup3_sentence_3_summary.csv\"\n","\n","def create_setup3(setup3_filepath):\n","  with open(setup3_filepath, 'w') as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"hadm_id\", \"source\", \"target\", \"discharge_summary\"])\n","    counter = 0\n","    for row in list_of_hadm_ids:\n","      if (counter == 9999):\n","        break\n","      hadm_id = row\n","      source = hadm_to_final_divides[hadm_id]\n","      summary_3_per_sec = get_final_summary(source)\n","      source_text = get_dict_str(source)\n","      summary_text = \".\".join(summary_3_per_sec)\n","      discharge_summary = hadm_to_discharge[hadm_id][-1][1]\n","      writer.writerow([hadm_id, source_text, summary_text, discharge_summary])\n","      counter += 1\n","\n","def create_modified_setup3(modified_setup3_filepath):\n","  with open(modified_setup3_filepath, 'w') as csvfile:\n","    fieldnames = [\"hadm_id\", \"source\", \"target\", \"discharge_summary\"]\n","    csvwriter = csv.DictWriter(csvfile, delimiter=',', fieldnames=fieldnames)\n","    csvwriter.writerow(dict((fn,fn) for fn in fieldnames))\n","    counter = 0\n","    test_array = []\n","    for row in list_of_hadm_ids:\n","      if (counter == 9999):\n","        break\n","      hadm_id = row\n","      if (hadm_id in hadm_to_nursing):\n","        curr_nursing = hadm_to_nursing[hadm_id]\n","        total_nursing = \"\"\n","        if len(curr_nursing) == 1:\n","          total_nursing = curr_nursing[0][1]\n","        elif len(curr_nursing) >= 2:\n","          total_nursing = curr_nursing[0][1]\n","          total_nursing = \"\\n\" + curr_nursing[-1][1]\n","        target_source = hadm_to_final_divides[hadm_id]\n","        summary_3_per_sec = get_final_summary(target_source)\n","        summary_text = \".\".join(summary_3_per_sec)\n","        test_array.append({\"source\": total_nursing, \"target\": summary_text, \"discharge_summary\": hadm_to_discharge[hadm_id][-1][1], \"hadm_id\": hadm_id})\n","        counter += 1\n","    for row in test_array:\n","      csvwriter.writerow(row)\n","\n","#create_setup3(setup3_filepath)\n","#create_modified_setup3(modified_setup3_filepath)"],"metadata":{"id":"KaHboji_T_-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["setup4_filepath = root_dir  + \"setup4_nursing_hist_section.csv\"\n","\n","def create_setup4(setup4_filepath):\n","  with open(setup4_filepath, 'w') as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"hadm_id\", \"source\", \"target\", \"discharge_summary\"])\n","    counter = 0\n","    print(len(hadm_to_nursing))\n","    for row in list_of_hadm_ids:\n","      if (counter == 9999):\n","        break\n","      hadm_id = row\n","      source = hadm_to_final_divides[hadm_id]\n","      if hadm_id in hadm_to_nursing:\n","        curr_nursing = hadm_to_nursing[hadm_id][-1][1]\n","        if \"Present Illness\" in source:\n","          hist_present = source[\"Present Illness\"]\n","          writer.writerow([hadm_id, curr_nursing, hist_present, hist_present])\n","          counter += 1\n","\n","#create_setup4(setup4_filepath)"],"metadata":{"id":"-viWrQ63vc6o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# another setup\n","# source: each nursing note in between _NNEWNOTE\n","# target: both sections in between _NNEWNOTE\n","# another setup -> modified setup 1\n","# put everything...not just 10,000\n","#entity or topic based extraction\n","def create_setup5(setup5_filepath):\n","  fieldnames = [\"hadm_id\", \"source\", \"target\", \"discharge_summary\"]\n","  with open(setup5_filepath, 'w') as csvfile:\n","    csvwriter = csv.DictWriter(csvfile, delimiter=',', fieldnames=fieldnames)\n","    csvwriter.writerow(dict((fn,fn) for fn in fieldnames))\n","    #writer.writerow([\"Source\", \"Target\"])\n","    test_array = []\n","    print(\"length of list of hadm ids\", list_of_hadm_ids)\n","    for row in list_of_hadm_ids:\n","      hadm_id = row\n","      if (hadm_id in hadm_to_nursing):\n","        curr_nursing = hadm_to_nursing[hadm_id]\n","        total_nursing = curr_nursing[0][1]\n","        for n in range(1, len(curr_nursing)):\n","          total_nursing += \"\\n_NNEWNOTE\\n\" + curr_nursing[n][1]\n","        test_array.append({\"source\": total_nursing, \"target\": hadm_to_discharge[hadm_id][-1][1], \"discharge_summary\": hadm_to_discharge[hadm_id][-1][1], \"hadm_id\": hadm_id})\n","          #writer.writerow({sources[t], targets[t]})\n","    for row in test_array:\n","      csvwriter.writerow(row)\n","\n","setup5_filepath = root_dir + \"setup5_nursing_discharge.csv\"\n","#create_setup5(setup5_filepath)"],"metadata":{"id":"9kFLnJ36vhMC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_setup6(setup6_filepath):\n","  fieldnames = [\"hadm_id\", \"source\", \"target\", \"discharge_summary\"]\n","  with open(setup6_filepath, 'w') as csvfile:\n","    csvwriter = csv.DictWriter(csvfile, delimiter=',', fieldnames=fieldnames)\n","    csvwriter.writerow(dict((fn,fn) for fn in fieldnames))\n","    #writer.writerow([\"Source\", \"Target\"])\n","    test_array = []\n","    for row in list_of_hadm_ids:\n","      hadm_id = row\n","      if (hadm_id in hadm_to_nursing):\n","        curr_nursing = hadm_to_nursing[hadm_id]\n","        total_nursing = curr_nursing[0][1]\n","        for n in range(1, len(curr_nursing)):\n","          total_nursing += \"\\n_NNEWNOTE\\n\" + curr_nursing[n][1]\n","        source = hadm_to_final_divides[hadm_id]\n","        if \"Present Illness\" in source and \"Discharge Instructions\" in source:\n","          hist_present = source[\"Present Illness\"]\n","          instr_present = source[\"Discharge Instructions\"]\n","          target = hist_present + \"\\n_NNEWNOTE\\n\" + instr_present\n","          test_array.append({\"source\": total_nursing, \"target\": target, \"discharge_summary\": target, \"hadm_id\": hadm_id})\n","          #writer.writerow({sources[t], targets[t]})\n","    for row in test_array:\n","      csvwriter.writerow(row)\n","\n","setup6_filepath = root_dir + \"setup6_nursing_hist_discharge.csv\"\n","#create_setup6(setup6_filepath)"],"metadata":{"id":"KeNUe8j-zoxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"-lH0c8ShstYQ"}}]}